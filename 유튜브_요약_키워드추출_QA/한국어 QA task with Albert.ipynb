{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "warming-converter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\82102\\\\Desktop\\\\nlp'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polished-cambodia",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8061152870070770646, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 14474280960\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 9273431993164810406\n",
       " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gpu 잡히는지 확인\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d9cd33",
   "metadata": {},
   "source": [
    "# 1. pipeline 이용해서"
   ]
  },
  {
   "cell_type": "raw",
   "id": "792fe35b",
   "metadata": {},
   "source": [
    "QA pipeline에 kcbert 모델을 넣어서 한국어 질의 응답을 해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fc1d23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, QuestionAnsweringPipeline\n",
    "import tensorflow as tf\n",
    "import tqdm.notebook\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e86d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertForQuestionAnswering: ['sop_classifier.classifier.weight', 'sop_classifier.classifier.bias', 'albert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFAlbertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFAlbertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"./Untitled Folder\", from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Untitled Folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ee84f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA pipeline 세팅\n",
    "qa = QuestionAnsweringPipeline(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80da4bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '윤여정은 1966년 연극 배우로 연기 경력을 시작하였고, 2021년 영화 《미나리》의 순자 역으로 아카데미 여우조연상을 수상했다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e8255fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '윤여정의 직업은?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edd5533f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0009075522539205849, 'start': 32, 'end': 40, 'answer': '2021년 영화'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acute-transcript",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.001071204082109034, 'start': 32, 'end': 40, 'answer': '2021년 영화'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(question='윤여정은 2021년 무엇을 했나?', context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "committed-actor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0010481227654963732, 'start': 32, 'end': 40, 'answer': '2021년 영화'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa(question='윤여정의 미나리에서의 역할은?', context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50eea6c2",
   "metadata": {},
   "source": [
    "# 2. 한국어 QA fine-tunning"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7da7941",
   "metadata": {},
   "source": [
    "한국어 데이터셋 (korquad) : https://korquad.github.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "451fc6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFAlbertForQuestionAnswering: ['sop_classifier.classifier.weight', 'sop_classifier.classifier.bias', 'albert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFAlbertForQuestionAnswering from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFAlbertForQuestionAnswering from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFAlbertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"./Untitled Folder\", from_pt=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./Untitled Folder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250141e3",
   "metadata": {},
   "source": [
    "## 데이터(KorQUAD) 전처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1612854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForQuestionAnswering, QuestionAnsweringPipeline\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e1237c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('korquad.json', <http.client.HTTPMessage at 0x1e2901d0490>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# korquad 파일 다운로드\n",
    "urllib.request.urlretrieve('https://korquad.github.io/dataset/KorQuAD_v1.0_train.json', 'korquad.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55b3293",
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad = json.load(open('korquad.json', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conscious-blake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paragraphs': [{'qas': [{'answers': [{'text': '교향곡', 'answer_start': 54}],\n",
       "     'id': '6566495-0-0',\n",
       "     'question': '바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?'},\n",
       "    {'answers': [{'text': '1악장', 'answer_start': 421}],\n",
       "     'id': '6566495-0-1',\n",
       "     'question': '바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?'},\n",
       "    {'answers': [{'text': '베토벤의 교향곡 9번', 'answer_start': 194}],\n",
       "     'id': '6566495-0-2',\n",
       "     'question': '바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?'},\n",
       "    {'answers': [{'text': '파우스트', 'answer_start': 15}],\n",
       "     'id': '6566518-0-0',\n",
       "     'question': '1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?'},\n",
       "    {'answers': [{'text': '합창교향곡', 'answer_start': 354}],\n",
       "     'id': '6566518-0-1',\n",
       "     'question': '파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?'},\n",
       "    {'answers': [{'text': '1839', 'answer_start': 0}],\n",
       "     'id': '5917067-0-0',\n",
       "     'question': '바그너가 파우스트를 처음으로 읽은 년도는?'},\n",
       "    {'answers': [{'text': '파리', 'answer_start': 410}],\n",
       "     'id': '5917067-0-1',\n",
       "     'question': '바그너가 처음 교향곡 작곡을 한 장소는?'},\n",
       "    {'answers': [{'text': '드레스덴', 'answer_start': 534}],\n",
       "     'id': '5917067-0-2',\n",
       "     'question': '바그너의 1악장의 초연은 어디서 연주되었는가?'}],\n",
       "   'context': '1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.'},\n",
       "  {'qas': [{'answers': [{'text': '한스 폰 뷜로', 'answer_start': 402}],\n",
       "     'id': '6566495-1-0',\n",
       "     'question': '바그너의 작품을 시인의 피로 쓰여졌다고 극찬한 것은 누구인가?'},\n",
       "    {'answers': [{'text': '리스트', 'answer_start': 23}],\n",
       "     'id': '6566495-1-1',\n",
       "     'question': '잊혀져 있는 파우스트 서곡 1악장을 부활시킨 것은 누구인가?'},\n",
       "    {'answers': [{'text': '20루이의 금', 'answer_start': 345}],\n",
       "     'id': '6566495-1-2',\n",
       "     'question': '바그너는 다시 개정된 총보를 얼마를 받고 팔았는가?'},\n",
       "    {'answers': [{'text': '리스트', 'answer_start': 23}],\n",
       "     'id': '6566518-1-0',\n",
       "     'question': '파우스트 교향곡을 부활시킨 사람은?'},\n",
       "    {'answers': [{'text': '한스 폰 뷜로', 'answer_start': 402}],\n",
       "     'id': '6566518-1-1',\n",
       "     'question': '파우스트 교향곡을 피아노 독주용으로 편곡한 사람은?'},\n",
       "    {'answers': [{'text': '리스트', 'answer_start': 23}],\n",
       "     'id': '5917067-1-0',\n",
       "     'question': '1악장을 부활시켜 연주한 사람은?'},\n",
       "    {'answers': [{'text': '한스 폰 뷜로', 'answer_start': 402}],\n",
       "     'id': '5917067-1-1',\n",
       "     'question': '파우스트 교향곡에 감탄하여 피아노곡으로 편곡한 사람은?'},\n",
       "    {'answers': [{'text': '1840년', 'answer_start': 3}],\n",
       "     'id': '5917067-1-2',\n",
       "     'question': '리스트가 바그너와 알게 된 연도는?'}],\n",
       "   'context': '한편 1840년부터 바그너와 알고 지내던 리스트가 잊혀져 있던 1악장을 부활시켜 1852년에 바이마르에서 연주했다. 이것을 계기로 바그너도 이 작품에 다시 관심을 갖게 되었고, 그 해 9월에는 총보의 반환을 요구하여 이를 서곡으로 간추린 다음 수정을 했고 브라이트코프흐 & 헤르텔 출판사에서 출판할 개정판도 준비했다. 1853년 5월에는 리스트가 이 작품이 수정되었다는 것을 인정했지만, 끝내 바그너의 출판 계획은 무산되고 말았다. 이후 1855년에 리스트가 자신의 작품 파우스트 교향곡을 거의 완성하여 그 사실을 바그너에게 알렸고, 바그너는 다시 개정된 총보를 리스트에게 보내고 브라이트코프흐 & 헤르텔 출판사에는 20루이의 금을 받고 팔았다. 또한 그의 작품을 “하나하나의 음표가 시인의 피로 쓰여졌다”며 극찬했던 한스 폰 뷜로가 그것을 피아노 독주용으로 편곡했는데, 리스트는 그것을 약간 변형되었을 뿐이라고 지적했다. 이 서곡의 총보 첫머리에는 파우스트 1부의 내용 중 한 구절을 인용하고 있다.'},\n",
       "  {'qas': [{'answers': [{'text': '주제, 동기', 'answer_start': 70}],\n",
       "     'id': '6566495-2-0',\n",
       "     'question': '서주에는 무엇이 암시되어 있는가?'},\n",
       "    {'answers': [{'text': '제1바이올린', 'answer_start': 148}],\n",
       "     'id': '6566495-2-1',\n",
       "     'question': '첫부분에는 어떤 악기를 사용해 더욱 명확하게 나타내는가?'},\n",
       "    {'answers': [{'text': '소나타 형식', 'answer_start': 272}],\n",
       "     'id': '6566495-2-2',\n",
       "     'question': '주요부는 어떤 형식으로 되어 있는가?'},\n",
       "    {'answers': [{'text': '저음 주제', 'answer_start': 102}],\n",
       "     'id': '6566518-2-0',\n",
       "     'question': '첫 부분의 주요주제를 암시하는 주제는?'},\n",
       "    {'answers': [{'text': 'D장조', 'answer_start': 409}],\n",
       "     'id': '6566518-2-1',\n",
       "     'question': '제2주제의 축소된 재현부의 조성은?'},\n",
       "    {'answers': [{'text': '4/4박자', 'answer_start': 35}],\n",
       "     'id': '5917067-2-0',\n",
       "     'question': '곡이 시작할때의 박자는?'},\n",
       "    {'answers': [{'text': '고뇌와 갈망 동기, 청춘의 사랑 동기', 'answer_start': 115}],\n",
       "     'id': '5917067-2-1',\n",
       "     'question': '이 곡의 주요 주제는?'},\n",
       "    {'answers': [{'text': 'D장조', 'answer_start': 409}],\n",
       "     'id': '5917067-2-2',\n",
       "     'question': '제 2주제에선 무슨 장조로 재현되는가?'}],\n",
       "   'context': '이 작품은 라단조, Sehr gehalten(아주 신중하게), 4/4박자의 부드러운 서주로 서주로 시작되는데, 여기에는 주요 주제, 동기의 대부분이 암시, 예고되어 있다. 첫 부분의 저음 주제는 주요 주제(고뇌와 갈망 동기, 청춘의 사랑 동기)를 암시하고 있으며, 제1바이올린으로 더욱 명확하게 나타난다. 또한 그것을 이어받는 동기도 중요한 역할을 한다. 여기에 새로운 소재가 더해진 뒤에 새로운 주제도 연주된다. 주요부는 Sehr bewegt(아주 격동적으로), 2/2박자의 자유로운 소나타 형식으로 매우 드라마틱한 구상과 유기적인 구성을 하고 있다. 여기에는 지금까지의 주제나 소재 외에도 오보에에 의한 선율과 제2주제를 떠올리게 하는 부차적인 주제가 더해지는데, 중간부에서는 약보3이 중심이 되고 제2주제는 축소된 재현부에서 D장조로 재현된다. 마지막에는 주요 주제를 회상하면서 조용히 마친다.'}],\n",
       " 'title': '파우스트_서곡'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korquad['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8830b3e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qas': [{'answers': [{'text': '교향곡', 'answer_start': 54}],\n",
       "   'id': '6566495-0-0',\n",
       "   'question': '바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?'},\n",
       "  {'answers': [{'text': '1악장', 'answer_start': 421}],\n",
       "   'id': '6566495-0-1',\n",
       "   'question': '바그너는 교향곡 작곡을 어디까지 쓴 뒤에 중단했는가?'},\n",
       "  {'answers': [{'text': '베토벤의 교향곡 9번', 'answer_start': 194}],\n",
       "   'id': '6566495-0-2',\n",
       "   'question': '바그너가 파우스트 서곡을 쓸 때 어떤 곡의 영향을 받았는가?'},\n",
       "  {'answers': [{'text': '파우스트', 'answer_start': 15}],\n",
       "   'id': '6566518-0-0',\n",
       "   'question': '1839년 바그너가 교향곡의 소재로 쓰려고 했던 책은?'},\n",
       "  {'answers': [{'text': '합창교향곡', 'answer_start': 354}],\n",
       "   'id': '6566518-0-1',\n",
       "   'question': '파우스트 서곡의 라단조 조성이 영향을 받은 베토벤의 곡은?'},\n",
       "  {'answers': [{'text': '1839', 'answer_start': 0}],\n",
       "   'id': '5917067-0-0',\n",
       "   'question': '바그너가 파우스트를 처음으로 읽은 년도는?'},\n",
       "  {'answers': [{'text': '파리', 'answer_start': 410}],\n",
       "   'id': '5917067-0-1',\n",
       "   'question': '바그너가 처음 교향곡 작곡을 한 장소는?'},\n",
       "  {'answers': [{'text': '드레스덴', 'answer_start': 534}],\n",
       "   'id': '5917067-0-2',\n",
       "   'question': '바그너의 1악장의 초연은 어디서 연주되었는가?'}],\n",
       " 'context': '1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para = korquad['data'][0]['paragraphs'][0]\n",
    "para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb81d017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 지문\n",
    "para['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99048254",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': [{'text': '교향곡', 'answer_start': 54}],\n",
       " 'id': '6566495-0-0',\n",
       " 'question': '바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문과 답\n",
    "qas = para['qas'][0]\n",
    "qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1333d52",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21104/4141548819.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m inputs = tokenizer(para['context'], \n\u001b[0m\u001b[0;32m      2\u001b[0m                    \u001b[0mqas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                    \u001b[0mtruncation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_max_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                    return_tensors='tf')\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(para['context'], \n",
    "                   qas['question'], \n",
    "                   truncation=True, \n",
    "                   max_length=tokenizer.model_max_length, \n",
    "                   return_tensors='tf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88aef32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = qas['answers'][0]\n",
    "\n",
    "# 글자의 위치\n",
    "start_char = q['answer_start']\n",
    "end_char = start_char + len(q['text']) - 1\n",
    "\n",
    "# 토큰의 위치\n",
    "start = inputs.char_to_token(0, start_char)\n",
    "end = inputs.char_to_token(0, end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6785de1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "# 글자의 위치\n",
    "print(start_char)\n",
    "print(end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6f938af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "# 토큰의 위치\n",
    "print(start)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "736fae35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "array([[   2,   21, 6355, 6336, 6672, 6545, 4209, 6424, 6686, 6259, 3484,\n",
       "        6518, 6362, 5283, 6349, 6350, 6419, 6377, 5022, 6537, 4783, 6322,\n",
       "        3517, 3662, 6463, 6271, 4092, 6537, 6263, 3630, 6628, 4779, 6335,\n",
       "        4445, 6608, 6354, 5381, 6369, 5369, 6351, 6362, 3489, 6719, 6342,\n",
       "        6377, 4574, 6628, 6259, 3965, 6377, 3401, 6259, 6265,   18, 4779,\n",
       "        4514, 6341, 4209, 6424, 6686, 6259,   21, 6355, 6336, 6355, 6545,\n",
       "        6271, 4316, 3831, 7283, 6353, 6354, 4380, 6410, 6394, 6410, 6377,\n",
       "        3774,    1, 4388, 7025, 6263, 6422, 4861, 6513, 6257, 4518, 6588,\n",
       "        6271, 3389, 6381, 6371, 6353, 6329, 4131, 6572, 6350, 6316, 7315,\n",
       "        6517, 6350, 6335, 4094, 6351, 6259, 5283, 6349, 6350, 6419, 6362,\n",
       "        4520, 6429, 6271, 3472, 6526, 6371, 6265, 6322, 5371, 6265,   18,\n",
       "        3935, 6483, 5283, 6317, 6271, 6369, 4590, 6408, 6584, 6587, 6362,\n",
       "        4908, 6969, 6354, 5283, 6317, 4769, 6445, 6363, 3477, 6577, 6445,\n",
       "        6365, 6263, 4659, 6274, 6298, 6259, 4244, 6316, 6965, 6362, 3489,\n",
       "        6719, 6342,   29, 6960, 6377, 3878, 6322, 3540, 6296, 3395, 6515,\n",
       "        6377, 4213, 6611, 6259, 6558,   16, 4779, 6484, 6263, 4779, 7077,\n",
       "        6314,   21, 6570, 6271, 5283, 6349, 6350, 6419, 6362, 4409, 6342,\n",
       "        6353, 6354, 4574, 6357, 6434, 4779, 4795, 6491, 6271, 4850, 6528,\n",
       "        6263, 6422, 6286, 4667, 6719, 6377, 3637, 6860, 6353, 6317, 6422,\n",
       "        6259, 3429, 6296, 4776, 6567, 6685, 4656, 6361, 6275, 4639, 6265,\n",
       "          18, 4656, 6341, 6362, 3976, 6365, 6334, 4850, 6295, 6362, 3455,\n",
       "        6349, 6271, 6286, 3517, 6362, 4824, 6341, 6271, 4823, 6932, 4788,\n",
       "        6259, 3429, 6690, 6727, 3777, 6869, 6483, 4830, 6444, 6262, 5361,\n",
       "        6354, 6351, 4518, 6362, 6275, 4212, 6430, 6847, 3429, 6263, 4590,\n",
       "        6426, 6422, 4244, 6316, 6965, 6362, 5376, 6391, 6375, 6719, 6342,\n",
       "        4850, 6295, 6362, 4667, 6719, 6377, 4213, 6296, 3429, 6377, 4267,\n",
       "        4469, 4788, 6265,   18, 3517, 7072, 6272, 3489, 6719, 6342, 4795,\n",
       "        6342, 6377,   21, 6355, 6336, 6672, 6545, 6281, 6339,   24, 6307,\n",
       "        6545, 6271, 3426, 7079, 5283, 6317, 6271, 6369, 4999, 6394, 6371,\n",
       "        6353, 6351,   21, 6445, 6347, 6377, 4576, 3867, 6271, 4884, 6365,\n",
       "        6371, 6265,   18, 3935, 6483, 4795, 6491, 6362, 4693, 6295, 6257,\n",
       "        3838, 6266, 6271, 3517, 6259, 4779, 4409, 6342,   12,   21, 6445,\n",
       "        6347,   13, 4767, 5283, 6317, 4769, 6445, 6363, 6362, 4659, 6274,\n",
       "        6476, 6271, 6369, 4659, 6274, 6685, 5283, 6419, 6283, 6380, 6361,\n",
       "        4879, 6403, 6298, 6321, 6353, 6351,   16, 4518, 6258, 6354, 6259,\n",
       "        4779, 6276, 6318, 6361, 6361, 6259, 4594, 6611, 6265,   18, 3450,\n",
       "        6273, 5043, 6401, 6296,   24, 6545, 4212, 6263, 4908, 6477, 5450,\n",
       "        6271, 3875, 6517, 6350, 7334, 6271, 6369, 4659, 6274, 6432, 6305,\n",
       "        6322, 4806, 6401, 6286, 4779, 6276, 6318, 6602, 6361, 6356,   16,\n",
       "        4779, 6452, 6271, 3517, 6379, 6354, 4220, 6547, 6432, 6322, 4097,\n",
       "        6611, 6265,   18, 3517, 4377, 6263, 6271, 3517, 6259, 4083, 6270,\n",
       "        6547, 6269, 4220, 7025, 6298, 6259, 3691, 7464, 6414, 6615, 6360,\n",
       "        6377, 4693, 6295, 6298, 6322, 5194, 6519, 6263, 6278, 6271, 6286,\n",
       "        4999, 6394, 6298, 6259, 3884, 4287, 6274, 6483, 4514, 6261, 6377,\n",
       "        4263, 6776,    3, 4209, 6424, 6686, 6259, 3484, 6518, 6362, 5283,\n",
       "        6349, 6350, 6419, 6335, 4783, 6322, 4165, 7046, 6377, 4574, 6322,\n",
       "        6367, 5388, 6259, 6275,   35,    3]], dtype=int32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "664b99c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'교향곡'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답을 실제 텍스트로 변환\n",
    "tokenizer.decode(inputs['input_ids'].numpy()[0, start:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7bc7f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['start_positions'] = [start]\n",
    "inputs['end_positions'] = [end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04057a96",
   "metadata": {},
   "source": [
    "## TFRecord로 저장\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7bb66f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def make_inputs(context, qas):\n",
    "    inputs = tokenizer(\n",
    "        context, \n",
    "        qas['question'], \n",
    "        truncation=True, \n",
    "        max_length=tokenizer.model_max_length)\n",
    "    q = qas['answers'][0]\n",
    "    start_char = q['answer_start']\n",
    "    end_char = start_char + len(q['text']) - 1\n",
    "    start = inputs.char_to_token(0, start_char)\n",
    "    end = inputs.char_to_token(0, end_char)\n",
    "    inputs['start_positions'] = [start]\n",
    "    inputs['end_positions'] = [end]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "219e8447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.4 s, sys: 231 ms, total: 54.6 s\n",
      "Wall time: 54.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 0\n",
    "filename = 'korquad.tfrecord'\n",
    "with tf.io.TFRecordWriter(filename) as writer:\n",
    "    for item in korquad['data']:   # 각 아이템 순환\n",
    "        for para in item['paragraphs']:  # 아이템마다 \n",
    "            context = para['context']\n",
    "            for qas in para['qas']:\n",
    "                inputs = make_inputs(context, qas)\n",
    "                if inputs['start_positions'][0] and inputs['end_positions'][0]:\n",
    "                    feature = {k: int_feature(v) for k, v in inputs.items()}\n",
    "                    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                    s = example.SerializeToString()\n",
    "                    writer.write(s)\n",
    "                    n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2aeddc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58675"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사례 수\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0aa7f",
   "metadata": {},
   "source": [
    "## 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bda09247",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_seq = tf.io.FixedLenSequenceFeature(shape=(), dtype=tf.int64, allow_missing=True)\n",
    "int_value = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "feature_description = {\n",
    "    'input_ids': int_seq,\n",
    "    'token_type_ids': int_seq,\n",
    "    'attention_mask': int_seq,\n",
    "    'start_positions': int_value,\n",
    "    'end_positions': int_value\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "629b591c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(example):\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example = {k : tf.cast(v, tf.int32) for k, v in example.items()}\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "556df875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# korquad 데이터셋 불러오기\n",
    "dataset = tf.data.TFRecordDataset(['korquad.tfrecord']).map(preproc).padded_batch(8)\n",
    "batch = next(iter(dataset))\n",
    "result = model(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7026fc4",
   "metadata": {},
   "source": [
    "## 수동으로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "registered-williams",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d3a487cc9c43fca8c6f7dae27d4a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1802 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33min 15s, sys: 2min 22s, total: 35min 38s\n",
      "Wall time: 1h 36min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 옵티마이저는 adam\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "\n",
    "n = 57653\n",
    "for batch in tqdm.notebook.tqdm(dataset, total=math.ceil(n / 32)):\n",
    "    with tf.GradientTape() as tape:\n",
    "        result = model(batch)\n",
    "        loss = tf.reduce_mean(result['loss'])\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables)) # loss가 감소하는 방향으로 파라미터 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "sharing-efficiency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.albert.modeling_tf_albert.TFAlbertForQuestionAnswering at 0x7f2ed4135048>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da76202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '윤여정은 1966년 연극 배우로 연기 경력을 시작하였고, 2021년 영화 《미나리》의 순자 역으로 아카데미 여우조연상을 수상했다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b5bd949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(question, context):\n",
    "    inputs = tokenizer(context, question, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    outputs = model(inputs)\n",
    "    start = tf.argmax(outputs.start_logits, axis=1).numpy()[0]\n",
    "    end = tf.argmax(outputs.end_logits, axis=1).numpy()[0]\n",
    "    return tokenizer.decode(inputs['input_ids'][0, start:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "suitable-arizona",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1966년'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('윤여정은 언제 데뷔했나?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "elect-milan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'연극 배우'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('윤여정의 직업은?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "hazardous-venice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'아카데미 여우조연상'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('윤여정이 2021년 받은 상은?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3d78292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미나리'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('윤여정의 출연작은?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a743667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'순자'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('윤여정이 미나리에서 맡았던 역할은?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "175cd28a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'미나리'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('윤여정은 2021년 무엇을 했는가?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eb4ede75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'순자'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('윤여정이 미나리에서 맡았던 배역은?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aba0372",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac8bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "naked-temperature",
   "metadata": {},
   "source": [
    "# 2. 한국어 QA fine-tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "structured-scientist",
   "metadata": {},
   "outputs": [],
   "source": [
    "korquad = json.load(open('./Untitled Folder/financial_mrc_test.json', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "immune-niagara",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '(금융경제신문 문혜원 기자)신한은행은 지난 6일 ▲본부...',\n",
       " 'url': None,\n",
       " 'context': '(금융경제신문 문혜원 기자)신한은행은 지난 6일 ▲본부부서 조직개편과 ▲현장 영업동력 강화 및 커뮤니티 지원에 중점을 둔 하반기 정기인사를 실시했다고 밝혔다.이번 조직개편은 디지털과 글로벌을 향한 신한만의 새로운 길을 만들어 ‘초(超)격차의 리딩뱅크’와 ‘World Class Bank 신한’의 꿈을 실현하기 위한 위성호 은행장의 전략을 바탕으로 진행됐다.조직개편의 주요 내용은 ▲디지털그룹 ▲GIB그룹 ▲대기업그룹 ▲글로벌사업본부 신설이다. 디지털그룹은 기존 분산되어 있던 디지털 인적·물적 역량 및 사업전략을 총괄하는 조직으로 신한은행의 디지털전략을 총괄하는 디지털전략본부, 모바일 채널 통합 플랫폼 구축을 위한 디지털채널본부, 빅데이터 분석역량 강화를 위한 빅데이터센터로 구성된다.또한 유연한 디지털 조직 운영을 위해 디지털그룹 내 A.I, 블록체인 등 총 7개의 랩(Lab)조직을 신설했다. GIB그룹과 대기업그룹은 자본시장 경쟁력 강화를 위해 기존 CIB그룹을 분리 확대 개편하면서 신설됐다.GIB그룹은 ‘원 신한(One Shinhan)’ 관점의 그룹경쟁력 강화를 위한 그룹 매트릭스 조직으로 사업부문 소속 직원들의 협업을 통해 역량을 집중할 계획이다.글로벌사업본부는 글로벌시장 경쟁력 강화를 위해 글로벌사업그룹 내 신설된 조직으로 앞으로 신한은행의 글로벌영업과 전략을 담당하게 된다.조직개편과 함께 진행된 이번 하반기 정기 인사는 조직개편 지원과 현장 영업동력 강화를 키워드로 실시됐다.디지털그룹 신설에 맞춰 디지털 역량 강화를 위해 선발 교육한 20여명의 대리ž행원급 인력을 실무부서에 배치했다. 아울러 현장의 전문성 강화를 위해 기업금융 심화과정 대상자 40여명을 선발하고 하반기 집중적인 전문 교육과정을 통해 기업금융 전문가로 육성할 계획이다.이밖에도 커뮤니티 단위의 자체 인력운용계획을 사전에 취합해 현장 요청사항 및 지역별 특수성을 감안해 정기인사에 반영했다.신한은행 관계자는 “이번 조직개편과 인사이동은 치열해지는 금융환경에서 더 높이 비상하는 신한은행이 되기 위해 업을 재 정의하자는 위성호 은행장의 철학이 반영됐다”며 “디지털과 글로벌 역량을 강화하고 금융그룹의 시너지를 창출해 업종의 경계도 국경의 경계도 없는 무한경쟁의 환경에서 앞서가는 신한은행이 될 수 있을 것”이라고 말했다.문혜원 기자  ft10@fetimes.co.kr',\n",
       " 'raw_html': '(금융경제신문 문혜원 기자)신한은행은 지난 6일 ▲본부부서 조직개편과 ▲현장 영업동력 강화 및 커뮤니티 지원에 중점을 둔 하반기 정기인사를 실시했다고 밝혔다.이번 조직개편은 디지털과 글로벌을 향한 신한만의 새로운 길을 만들어 ‘초(超)격차의 리딩뱅크’와 ‘World Class Bank 신한’의 꿈을 실현하기 위한 위성호 은행장의 전략을 바탕으로 진행됐다.조직개편의 주요 내용은 ▲디지털그룹 ▲GIB그룹 ▲대기업그룹 ▲글로벌사업본부 신설이다. 디지털그룹은 기존 분산되어 있던 디지털 인적·물적 역량 및 사업전략을 총괄하는 조직으로 신한은행의 디지털전략을 총괄하는 디지털전략본부, 모바일 채널 통합 플랫폼 구축을 위한 디지털채널본부, 빅데이터 분석역량 강화를 위한 빅데이터센터로 구성된다.또한 유연한 디지털 조직 운영을 위해 디지털그룹 내 A.I, 블록체인 등 총 7개의 랩(Lab)조직을 신설했다. GIB그룹과 대기업그룹은 자본시장 경쟁력 강화를 위해 기존 CIB그룹을 분리 확대 개편하면서 신설됐다.GIB그룹은 ‘원 신한(One Shinhan)’ 관점의 그룹경쟁력 강화를 위한 그룹 매트릭스 조직으로 사업부문 소속 직원들의 협업을 통해 역량을 집중할 계획이다.글로벌사업본부는 글로벌시장 경쟁력 강화를 위해 글로벌사업그룹 내 신설된 조직으로 앞으로 신한은행의 글로벌영업과 전략을 담당하게 된다.조직개편과 함께 진행된 이번 하반기 정기 인사는 조직개편 지원과 현장 영업동력 강화를 키워드로 실시됐다.디지털그룹 신설에 맞춰 디지털 역량 강화를 위해 선발 교육한 20여명의 대리ž행원급 인력을 실무부서에 배치했다. 아울러 현장의 전문성 강화를 위해 기업금융 심화과정 대상자 40여명을 선발하고 하반기 집중적인 전문 교육과정을 통해 기업금융 전문가로 육성할 계획이다.이밖에도 커뮤니티 단위의 자체 인력운용계획을 사전에 취합해 현장 요청사항 및 지역별 특수성을 감안해 정기인사에 반영했다.신한은행 관계자는 “이번 조직개편과 인사이동은 치열해지는 금융환경에서 더 높이 비상하는 신한은행이 되기 위해 업을 재 정의하자는 위성호 은행장의 철학이 반영됐다”며 “디지털과 글로벌 역량을 강화하고 금융그룹의 시너지를 창출해 업종의 경계도 국경의 경계도 없는 무한경쟁의 환경에서 앞서가는 신한은행이 될 수 있을 것”이라고 말했다.문혜원 기자  ft10@fetimes.co.kr',\n",
       " 'qas': [{'id': '0',\n",
       "   'question': '위성호 은행장에 의해 개편된 신설조직 중, ‘원 신한(One Shinhan)’ 관점의 그룹경쟁력 강화를 위한 그룹 매트릭스 조직으로 사업부문 소속 직원들의 협업을 통해 역량을 집중할 계획을 가진 그룹명은?',\n",
       "   'answer': {'text': 'GIB그룹',\n",
       "    'answer_start': 504,\n",
       "    'html_answer_text': 'GIB그룹',\n",
       "    'html_answer_start': 504}},\n",
       "  {'id': '1',\n",
       "   'question': '‘초(超)격차의 리딩뱅크’와 ‘World Class Bank 신한’의 꿈을 실현하기 위해 전략적 조직개편을 진행한 신한은행의 은행장 이름은?',\n",
       "   'answer': {'text': '위성호 은행장',\n",
       "    'answer_start': 176,\n",
       "    'html_answer_text': '위성호 은행장',\n",
       "    'html_answer_start': 176}}]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korquad['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "political-citizen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(금융경제신문 문혜원 기자)신한은행은 지난 6일 ▲본부부서 조직개편과 ▲현장 영업동력 강화 및 커뮤니티 지원에 중점을 둔 하반기 정기인사를 실시했다고 밝혔다.이번 조직개편은 디지털과 글로벌을 향한 신한만의 새로운 길을 만들어 ‘초(超)격차의 리딩뱅크’와 ‘World Class Bank 신한’의 꿈을 실현하기 위한 위성호 은행장의 전략을 바탕으로 진행됐다.조직개편의 주요 내용은 ▲디지털그룹 ▲GIB그룹 ▲대기업그룹 ▲글로벌사업본부 신설이다. 디지털그룹은 기존 분산되어 있던 디지털 인적·물적 역량 및 사업전략을 총괄하는 조직으로 신한은행의 디지털전략을 총괄하는 디지털전략본부, 모바일 채널 통합 플랫폼 구축을 위한 디지털채널본부, 빅데이터 분석역량 강화를 위한 빅데이터센터로 구성된다.또한 유연한 디지털 조직 운영을 위해 디지털그룹 내 A.I, 블록체인 등 총 7개의 랩(Lab)조직을 신설했다. GIB그룹과 대기업그룹은 자본시장 경쟁력 강화를 위해 기존 CIB그룹을 분리 확대 개편하면서 신설됐다.GIB그룹은 ‘원 신한(One Shinhan)’ 관점의 그룹경쟁력 강화를 위한 그룹 매트릭스 조직으로 사업부문 소속 직원들의 협업을 통해 역량을 집중할 계획이다.글로벌사업본부는 글로벌시장 경쟁력 강화를 위해 글로벌사업그룹 내 신설된 조직으로 앞으로 신한은행의 글로벌영업과 전략을 담당하게 된다.조직개편과 함께 진행된 이번 하반기 정기 인사는 조직개편 지원과 현장 영업동력 강화를 키워드로 실시됐다.디지털그룹 신설에 맞춰 디지털 역량 강화를 위해 선발 교육한 20여명의 대리ž행원급 인력을 실무부서에 배치했다. 아울러 현장의 전문성 강화를 위해 기업금융 심화과정 대상자 40여명을 선발하고 하반기 집중적인 전문 교육과정을 통해 기업금융 전문가로 육성할 계획이다.이밖에도 커뮤니티 단위의 자체 인력운용계획을 사전에 취합해 현장 요청사항 및 지역별 특수성을 감안해 정기인사에 반영했다.신한은행 관계자는 “이번 조직개편과 인사이동은 치열해지는 금융환경에서 더 높이 비상하는 신한은행이 되기 위해 업을 재 정의하자는 위성호 은행장의 철학이 반영됐다”며 “디지털과 글로벌 역량을 강화하고 금융그룹의 시너지를 창출해 업종의 경계도 국경의 경계도 없는 무한경쟁의 환경에서 앞서가는 신한은행이 될 수 있을 것”이라고 말했다.문혜원 기자  ft10@fetimes.co.kr'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 지문\n",
    "para = korquad['data'][0]['context']\n",
    "para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "compact-vegetable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '0',\n",
       " 'question': '위성호 은행장에 의해 개편된 신설조직 중, ‘원 신한(One Shinhan)’ 관점의 그룹경쟁력 강화를 위한 그룹 매트릭스 조직으로 사업부문 소속 직원들의 협업을 통해 역량을 집중할 계획을 가진 그룹명은?',\n",
       " 'answer': {'text': 'GIB그룹',\n",
       "  'answer_start': 504,\n",
       "  'html_answer_text': 'GIB그룹',\n",
       "  'html_answer_start': 504}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 질문과 답\n",
    "qas = korquad['data'][0]['qas'][0]\n",
    "qas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "facial-lithuania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'위성호 은행장에 의해 개편된 신설조직 중, ‘원 신한(One Shinhan)’ 관점의 그룹경쟁력 강화를 위한 그룹 매트릭스 조직으로 사업부문 소속 직원들의 협업을 통해 역량을 집중할 계획을 가진 그룹명은?'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qas['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "based-gibraltar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "array([[   2,   12, 3523, 6784, 6429, 6258, 6444, 6282, 4168, 6637, 6363,\n",
       "        3529, 6367,   13, 4516, 6483, 6296, 6603, 6296, 4908, 6477,   26,\n",
       "        6531,  453, 6541, 6281, 6281, 6369, 4850, 6753, 6310, 6428, 6257,\n",
       "         453, 6577, 6347, 4667, 6293, 6346, 6440, 3400, 6328, 4207, 5112,\n",
       "        6978, 6426, 6327, 4908, 6363, 6271, 4884, 6451, 6377, 3858, 5369,\n",
       "        6436, 6341, 4830, 6341, 6360, 6376, 6335, 4518, 6266, 6371, 6265,\n",
       "        6322, 4215, 6967, 6265,   18, 4779, 6960, 4850, 6753, 6310, 6428,\n",
       "        6296, 3886, 6361, 7075, 6257, 3521, 6354, 6619, 6377, 5393, 6483,\n",
       "        4516, 6483, 6356, 6362, 4390, 6354, 6345, 3533, 6377, 4094, 6368,\n",
       "        6318,  318, 5043,   12, 2987,   13, 3447, 6320, 6362, 4083, 7034,\n",
       "        7546, 6587,  319, 4691,  318,   59, 6460, 6290, 6386, 6288,   39,\n",
       "        6386, 6622, 6663, 6663,   38, 6622, 6461, 6287, 4516, 6483,  319,\n",
       "        4776, 3608, 6377, 4518, 6577, 6298, 6341, 4747, 6483, 4747, 6295,\n",
       "        6519, 4766, 6603, 6347, 6362, 4824, 6632, 6377, 4209, 6280, 6353,\n",
       "        6354, 4910, 6603, 6961, 6265,   18, 4850, 6753, 6310, 6428, 6362,\n",
       "        4877, 6499, 3662, 6463, 6296,  453, 6467, 6361, 7075, 6424, 6459,\n",
       "         453, 6824, 6643, 6745, 6424, 6459,  453, 6379, 6341, 6293, 6424,\n",
       "        6459,  453, 7084, 6354, 6619, 6376, 6293, 6541, 6281, 4516, 6402,\n",
       "        6263, 6265,   18, 3886, 6361, 7075, 6424, 6459, 6296, 3529, 6796,\n",
       "        4287, 6292, 6432, 6318, 4788, 6299, 3886, 6361, 7075, 4781, 6262,\n",
       "         108, 4170, 6262, 4657, 6589, 4207, 4377, 6293, 6410, 6632, 6377,\n",
       "        5050, 7116, 6298, 6259, 4850, 6753, 6353, 6354, 4516, 6483, 6296,\n",
       "        6603, 6362, 3886, 6361, 7075, 6410, 6632, 6377, 5050, 7116, 6298,\n",
       "        6259, 3886, 6361, 7075, 6410, 6632, 6541, 6281,   16, 4149, 6510,\n",
       "        6531, 5009, 6535, 5241, 6344, 5358, 7153, 7266, 3492, 6291, 6377,\n",
       "        4747, 6483, 3886, 6361, 7075, 6496, 6535, 6541, 6281,   16, 4308,\n",
       "        6558, 6263, 6339, 4287, 6455, 6486, 6589, 3400, 6328, 6335, 4747,\n",
       "        6483, 4308, 6558, 6263, 6339, 6479, 6339, 6354, 3492, 6295, 6847,\n",
       "        6265,   18, 3935, 6483, 4755, 6401, 6483, 3886, 6361, 7075, 4850,\n",
       "        6753, 4723, 6430, 6377, 4747, 6314, 3886, 6361, 7075, 6424, 6459,\n",
       "        3662,   37,   18,   45,   16, 4305, 6312, 6411, 6360, 3884, 5050,\n",
       "          27, 6310, 6362, 3993,   12,   48, 6622, 6704,   13, 4850, 6753,\n",
       "        6377, 4516, 6402, 6371, 6265,   18,   43, 6643, 6745, 6424, 6459,\n",
       "        6257, 3791, 6341, 6293, 6424, 6459, 6296, 4794, 6541, 6266, 6347,\n",
       "        3455, 6962, 6440, 3400, 6328, 6335, 4747, 6314, 3529, 6796,   39,\n",
       "        6643, 6745, 6424, 6459, 6377, 4287, 6317, 5433, 6379, 3407, 6428,\n",
       "        6298, 6607, 6369, 4516, 6402, 6961, 6265,   18,   43, 6643, 6745,\n",
       "        6424, 6459, 6296,  318, 4732, 4516, 6483,   12,   51, 6461, 6650,\n",
       "          55, 6383, 6289,    3, 4747, 6295, 6519, 4766, 6603, 6347, 6271,\n",
       "        4776, 6314, 3407, 6428, 6847, 4516, 6402, 6334, 6753, 4884,   16,\n",
       "         318, 4732, 4516, 6483,   12,   51, 6461, 6650,   55, 6383, 6289,\n",
       "        6461, 6383, 6622, 6461,   13,  319, 3477, 6451, 6362, 3517, 6459,\n",
       "        6429, 6962, 6440, 3400, 6328, 6335, 4747, 6483, 3517, 6459, 4107,\n",
       "        6419, 6894, 6350, 4850, 6753, 6353, 6354, 4377, 6293, 6281, 6282,\n",
       "        4445, 6710, 4909, 6363, 6368, 6362, 5418, 6293, 6377, 5241, 6314,\n",
       "        4657, 6589, 6377, 4915, 6393, 6685, 3458, 6516, 6377, 3389, 6434,\n",
       "        3517, 6459, 6515, 6296,   35,    3]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(para , \n",
    "                   qas['question'], \n",
    "                   truncation=True, \n",
    "                   max_length=tokenizer.model_max_length, \n",
    "                   return_tensors='tf')\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "plain-matthew",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = qas['answer']\n",
    "\n",
    "# 글자의 위치\n",
    "start_char = q['answer_start']\n",
    "end_char = start_char + len(q['text']) - 1\n",
    "\n",
    "# 토큰의 위치\n",
    "start = inputs.char_to_token(0, start_char)\n",
    "end = inputs.char_to_token(0, end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "accomplished-complexity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "508\n"
     ]
    }
   ],
   "source": [
    "# 글자의 위치\n",
    "print(start_char)\n",
    "print(end_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "organized-academy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404\n",
      "408\n"
     ]
    }
   ],
   "source": [
    "# 토큰의 위치\n",
    "print(start)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "continental-radio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
       "array([[   2,   12, 3523, 6784, 6429, 6258, 6444, 6282, 4168, 6637, 6363,\n",
       "        3529, 6367,   13, 4516, 6483, 6296, 6603, 6296, 4908, 6477,   26,\n",
       "        6531,  453, 6541, 6281, 6281, 6369, 4850, 6753, 6310, 6428, 6257,\n",
       "         453, 6577, 6347, 4667, 6293, 6346, 6440, 3400, 6328, 4207, 5112,\n",
       "        6978, 6426, 6327, 4908, 6363, 6271, 4884, 6451, 6377, 3858, 5369,\n",
       "        6436, 6341, 4830, 6341, 6360, 6376, 6335, 4518, 6266, 6371, 6265,\n",
       "        6322, 4215, 6967, 6265,   18, 4779, 6960, 4850, 6753, 6310, 6428,\n",
       "        6296, 3886, 6361, 7075, 6257, 3521, 6354, 6619, 6377, 5393, 6483,\n",
       "        4516, 6483, 6356, 6362, 4390, 6354, 6345, 3533, 6377, 4094, 6368,\n",
       "        6318,  318, 5043,   12, 2987,   13, 3447, 6320, 6362, 4083, 7034,\n",
       "        7546, 6587,  319, 4691,  318,   59, 6460, 6290, 6386, 6288,   39,\n",
       "        6386, 6622, 6663, 6663,   38, 6622, 6461, 6287, 4516, 6483,  319,\n",
       "        4776, 3608, 6377, 4518, 6577, 6298, 6341, 4747, 6483, 4747, 6295,\n",
       "        6519, 4766, 6603, 6347, 6362, 4824, 6632, 6377, 4209, 6280, 6353,\n",
       "        6354, 4910, 6603, 6961, 6265,   18, 4850, 6753, 6310, 6428, 6362,\n",
       "        4877, 6499, 3662, 6463, 6296,  453, 6467, 6361, 7075, 6424, 6459,\n",
       "         453, 6824, 6643, 6745, 6424, 6459,  453, 6379, 6341, 6293, 6424,\n",
       "        6459,  453, 7084, 6354, 6619, 6376, 6293, 6541, 6281, 4516, 6402,\n",
       "        6263, 6265,   18, 3886, 6361, 7075, 6424, 6459, 6296, 3529, 6796,\n",
       "        4287, 6292, 6432, 6318, 4788, 6299, 3886, 6361, 7075, 4781, 6262,\n",
       "         108, 4170, 6262, 4657, 6589, 4207, 4377, 6293, 6410, 6632, 6377,\n",
       "        5050, 7116, 6298, 6259, 4850, 6753, 6353, 6354, 4516, 6483, 6296,\n",
       "        6603, 6362, 3886, 6361, 7075, 6410, 6632, 6377, 5050, 7116, 6298,\n",
       "        6259, 3886, 6361, 7075, 6410, 6632, 6541, 6281,   16, 4149, 6510,\n",
       "        6531, 5009, 6535, 5241, 6344, 5358, 7153, 7266, 3492, 6291, 6377,\n",
       "        4747, 6483, 3886, 6361, 7075, 6496, 6535, 6541, 6281,   16, 4308,\n",
       "        6558, 6263, 6339, 4287, 6455, 6486, 6589, 3400, 6328, 6335, 4747,\n",
       "        6483, 4308, 6558, 6263, 6339, 6479, 6339, 6354, 3492, 6295, 6847,\n",
       "        6265,   18, 3935, 6483, 4755, 6401, 6483, 3886, 6361, 7075, 4850,\n",
       "        6753, 4723, 6430, 6377, 4747, 6314, 3886, 6361, 7075, 6424, 6459,\n",
       "        3662,   37,   18,   45,   16, 4305, 6312, 6411, 6360, 3884, 5050,\n",
       "          27, 6310, 6362, 3993,   12,   48, 6622, 6704,   13, 4850, 6753,\n",
       "        6377, 4516, 6402, 6371, 6265,   18,   43, 6643, 6745, 6424, 6459,\n",
       "        6257, 3791, 6341, 6293, 6424, 6459, 6296, 4794, 6541, 6266, 6347,\n",
       "        3455, 6962, 6440, 3400, 6328, 6335, 4747, 6314, 3529, 6796,   39,\n",
       "        6643, 6745, 6424, 6459, 6377, 4287, 6317, 5433, 6379, 3407, 6428,\n",
       "        6298, 6607, 6369, 4516, 6402, 6961, 6265,   18,   43, 6643, 6745,\n",
       "        6424, 6459, 6296,  318, 4732, 4516, 6483,   12,   51, 6461, 6650,\n",
       "          55, 6383, 6289,    3, 4747, 6295, 6519, 4766, 6603, 6347, 6271,\n",
       "        4776, 6314, 3407, 6428, 6847, 4516, 6402, 6334, 6753, 4884,   16,\n",
       "         318, 4732, 4516, 6483,   12,   51, 6461, 6650,   55, 6383, 6289,\n",
       "        6461, 6383, 6622, 6461,   13,  319, 3477, 6451, 6362, 3517, 6459,\n",
       "        6429, 6962, 6440, 3400, 6328, 6335, 4747, 6483, 3517, 6459, 4107,\n",
       "        6419, 6894, 6350, 4850, 6753, 6353, 6354, 4377, 6293, 6281, 6282,\n",
       "        4445, 6710, 4909, 6363, 6368, 6362, 5418, 6293, 6377, 5241, 6314,\n",
       "        4657, 6589, 6377, 4915, 6393, 6685, 3458, 6516, 6377, 3389, 6434,\n",
       "        3517, 6459, 6515, 6296,   35,    3]], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "available-blind",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GIB그룹'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정답을 실제 텍스트로 변환\n",
    "tokenizer.decode(inputs['input_ids'].numpy()[0, start:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "leading-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['start_positions'] = [start]\n",
    "inputs['end_positions'] = [end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polish-discharge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "sublime-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
    "\n",
    "def make_inputs(context, qas):\n",
    "    inputs = tokenizer(\n",
    "        context, \n",
    "        qas['question'], \n",
    "        truncation=True, \n",
    "        max_length=tokenizer.model_max_length)\n",
    "    q = qas['answer']\n",
    "    start_char = q['answer_start']\n",
    "    end_char = start_char + len(q['text']) - 1\n",
    "    start = inputs.char_to_token(0, start_char)\n",
    "    end = inputs.char_to_token(0, end_char)\n",
    "    inputs['start_positions'] = [start]\n",
    "    inputs['end_positions'] = [end]\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "opposed-country",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 555 ms, sys: 0 ns, total: 555 ms\n",
      "Wall time: 554 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n = 0\n",
    "filename = 'korquad.tfrecord1'\n",
    "with tf.io.TFRecordWriter(filename) as writer:\n",
    "    for item in korquad['data']:   # 각 아이템 순환\n",
    "        context = item['context']  # 아이템마다 \n",
    "            \n",
    "        for qas in item['qas']:\n",
    "            inputs = make_inputs(context, qas)\n",
    "            if inputs['start_positions'][0] and inputs['end_positions'][0]:\n",
    "                feature = {k: int_feature(v) for k, v in inputs.items()}\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                s = example.SerializeToString()\n",
    "                writer.write(s)\n",
    "                n += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "shared-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_seq = tf.io.FixedLenSequenceFeature(shape=(), dtype=tf.int64, allow_missing=True)\n",
    "int_value = tf.io.FixedLenFeature(shape=(), dtype=tf.int64)\n",
    "feature_description = {\n",
    "    'input_ids': int_seq,\n",
    "    'token_type_ids': int_seq,\n",
    "    'attention_mask': int_seq,\n",
    "    'start_positions': int_value,\n",
    "    'end_positions': int_value\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "regulated-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(example):\n",
    "    example = tf.io.parse_single_example(example, feature_description)\n",
    "    example = {k : tf.cast(v, tf.int32) for k, v in example.items()}\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aboriginal-acceptance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# korquad 데이터셋 불러오기\n",
    "dataset = tf.data.TFRecordDataset(['korquad.tfrecord1']).map(preproc).padded_batch(8)\n",
    "batch = next(iter(dataset))\n",
    "result = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "revolutionary-holder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf247720f2f4e598bfff6495a78bdf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 s, sys: 1.02 s, total: 12.7 s\n",
      "Wall time: 36.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 옵티마이저는 adam\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "\n",
    "n = 333\n",
    "for batch in tqdm.notebook.tqdm(dataset, total=math.ceil(n / 32)):\n",
    "    with tf.GradientTape() as tape:\n",
    "        result = model(batch)\n",
    "        loss = tf.reduce_mean(result['loss'])\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grads, model.trainable_variables)) # loss가 감소하는 방향으로 파라미터 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "efficient-wednesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<transformers.models.albert.modeling_tf_albert.TFAlbertForQuestionAnswering at 0x7f2ed4135048>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "robust-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '방카슈랑스는 금융의 겸업화 추세에 부응하여 금융산업의 선진화를 도모하고 금융소비자의 편익을 위하여 도입되었습니다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "crazy-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(question, context):\n",
    "    inputs = tokenizer(context, question, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    outputs = model(inputs)\n",
    "    start = tf.argmax(outputs.start_logits, axis=1).numpy()[0]\n",
    "    end = tf.argmax(outputs.end_logits, axis=1).numpy()[0]\n",
    "    return tokenizer.decode(inputs['input_ids'][0, start:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "different-snapshot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'방카슈랑스'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('금융의 겸업화 추세에 부응하여 금융산업의 선진화를 도모하고 금융소비자의 편익을 위하여 도입된 것은?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "lightweight-antarctica",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = '10일 국내 가상화폐 시장에서 비트코인이 급락하며 4천만원선까지 위협하고 있다.이날 오전 9시 35분 가상화폐 거래소 업비트에서 1비트코인 가격은 4천36만4천원으로, 24시간 만에 10.06% 내렸다. 비트코인이 4천만원까지 내려온 것은 지난해 5월 대폭락 직후인 7월 26일로부터 1년 9개월여 만의 처음이다.같은 시간 빗썸에서도 10.34% 하락하며 4천12만1천원에 거래되고 있다. 이는 최근 비트코인이 동조하는 뉴욕 증시가 간밤 스태그플레이션(고물가·저성장) 공포 때문에 크게 하락한 영향으로 풀이된다. 3대 지수 중 기술주 중심 나스닥 지수는 4.29% 떨어졌다. 52주 전 최고치와 대비하면 28%나 하락한 수준이다. 스탠더드앤드푸어스(S&P)500지수 역시 종가 기준 지난해 3월 31일 이후 처음으로 4,000선 아래로 내려갔다.이에 미국에서도 한때 비트코인 가격은 지난해 7월 말 이후 처음으로 3만달러 선 아래로 내려가기도 했다.국내 시가총액 규모 2위인 이더리움도 10%대로 하락하며 업비트에서 한때 296만8천원까지 떨어져 지난 2월 25일 이후 2개월여 만에 300만원선을 밑돌기도 했다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "induced-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qa(question, context):\n",
    "    inputs = tokenizer(context, question, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    outputs = model(inputs)\n",
    "    start = tf.argmax(outputs.start_logits, axis=1).numpy()[0]\n",
    "    end = tf.argmax(outputs.end_logits, axis=1).numpy()[0]\n",
    "    return tokenizer.decode(inputs['input_ids'][0, start:end+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "rough-heading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4천만원선'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('비트코인은 어디까지 급락했나?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "worst-scale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4. 29 %'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa('현재 기술주 중심 나스닥 지수는 얼마나 떨어졌나?', context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-pursuit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-delay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-amsterdam",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-grounds",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
